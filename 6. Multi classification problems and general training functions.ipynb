{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多分类问题与通用训练函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax函数：** 将输出值映射到0-1之间，并且所有输出的和为1，常用于多分类问题。当只有两个类别时，对数几率函数和softmax函数是等价的。\n",
    "\n",
    "**pytorch交叉熵：** 对于多分类问题，pytorch提供了交叉熵函数（nn.CrossEntropyLoss和nn.NLLLoss），其中nn.CrossEntropyLoss内部实现了softmax函数，并且对标签值进行了one-hot编码，而nn.NLLLoss需要手动添加softmax函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "0           1           5.1          3.5           1.4          0.2  setosa\n",
       "1           2           4.9          3.0           1.4          0.2  setosa\n",
       "2           3           4.7          3.2           1.3          0.2  setosa\n",
       "3           4           4.6          3.1           1.5          0.2  setosa\n",
       "4           5           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据集，鸢尾花数据集\n",
    "data = pd.read_csv('./dataset/iris.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64), Index(['setosa', 'versicolor', 'virginica'], dtype='object'))\n"
     ]
    }
   ],
   "source": [
    "print(data.Species.unique())\n",
    "print(pd.factorize(data.Species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width  Species\n",
       "0             1           5.1          3.5           1.4          0.2        0\n",
       "1             2           4.9          3.0           1.4          0.2        0\n",
       "2             3           4.7          3.2           1.3          0.2        0\n",
       "3             4           4.6          3.1           1.5          0.2        0\n",
       "4             5           5.0          3.6           1.4          0.2        0\n",
       "..          ...           ...          ...           ...          ...      ...\n",
       "145         146           6.7          3.0           5.2          2.3        2\n",
       "146         147           6.3          2.5           5.0          1.9        2\n",
       "147         148           6.5          3.0           5.2          2.0        2\n",
       "148         149           6.2          3.4           5.4          2.3        2\n",
       "149         150           5.9          3.0           5.1          1.8        2\n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Species'] = pd.factorize(data.Species)[0] # 将标签值转换为数字\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150, 1)\n"
     ]
    }
   ],
   "source": [
    "# 分离特征值和标签值\n",
    "X = data.iloc[:, 1: -1].values # 特征值\n",
    "print(X.shape)\n",
    "Y = data.Species.values.reshape(-1, 1) # 标签值\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y)\n",
    "# 数据归一化，ndarray转换为tensor\n",
    "train_x = torch.from_numpy(train_x).type(torch.FloatTensor)\n",
    "train_y = torch.from_numpy(train_y).type(torch.FloatTensor)\n",
    "test_x = torch.from_numpy(test_x).type(torch.FloatTensor)\n",
    "test_y = torch.from_numpy(test_y).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_len = 150\n",
      "train_len = 112\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"data_len = \" + str(len(data)))\n",
    "batch = 8\n",
    "\n",
    "train_ds = TensorDataset(train_x, train_y)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch, shuffle=True)\n",
    "\n",
    "test_ds = TensorDataset(test_x, test_y)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch)\n",
    "\n",
    "print(\"train_len = \" + str(len(train_dl.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (lin_1): Linear(in_features=4, out_features=32, bias=True)\n",
       "  (lin_2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (lin_3): Linear(in_features=32, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F # 函数式API，调用方便使代码更简洁\n",
    "class Model(nn.Module):  # 继承nn.Module\n",
    "    def __init__(self):     # 初始化所有的层\n",
    "        super().__init__()  # 继承父类中所有的属性和方法\n",
    "        self.lin_1 = nn.Linear(4, 32)  # 定义第一层线性层，输入维度为4，输出维度为32\n",
    "        self.lin_2 = nn.Linear(32, 32)  # 定义第二层线性层，输入维度为32，输出维度为32\n",
    "        self.lin_3 = nn.Linear(32, 3)   # 定义第三层线性层，输入维度为32，输出维度为3\n",
    "    def forward(self, input):   # 前向传播函数，定义模型的运算过程，覆盖父类中的forward方法\n",
    "        x = F.relu(self.lin_1(input))   # 将输入数据传入第一层线性层，并使用ReLU激活函数\n",
    "        x = F.relu(self.lin_2(x))       # 将激活后的数据传入第二层线性层，并使用ReLU激活函数\n",
    "        x = self.lin_3(x)               # 多分类问题，最后一层不需要激活函数\n",
    "        return x\n",
    "\n",
    "# 实例化模型\n",
    "model = Model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4]) torch.Size([8, 1])\n",
      "torch.Size([8, 3])\n",
      "tensor([[ 0.2064, -0.3155,  0.0284],\n",
      "        [ 0.2150, -0.3592,  0.0384],\n",
      "        [ 0.1972, -0.3582,  0.0362],\n",
      "        [ 0.0602, -0.0603, -0.1487],\n",
      "        [ 0.0784, -0.0824, -0.1357],\n",
      "        [ 0.0838, -0.0990, -0.1046],\n",
      "        [ 0.0706, -0.0581, -0.1245],\n",
      "        [ 0.2440, -0.4178,  0.0532]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# 理解模型的预测结果\n",
    "# 获取一个batch的数据\n",
    "input_batch, label_batch = next(iter(train_dl)) # iter()函数返回一个迭代器，next()函数返回一个批次的张量\n",
    "print(input_batch.shape, label_batch.shape)\n",
    "# 前向传播\n",
    "y_pred = model(input_batch)\n",
    "print(y_pred.shape)\n",
    "print(y_pred)\n",
    "# 查看预测结果\n",
    "print(torch.argmax(y_pred, dim=1)) # argmax()函数返回张量中最大值的索引，dim=1表示在每一行中找到最大值的索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    y_pred = torch.argmax(y_pred, dim=1)\n",
    "    acc = (y_pred == y_true).float().mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for x, y in train_dl:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        epoch_accuracy = accuracy(model(train_x), train_y)\n",
    "        epoch_loss = loss_fn(model(train_x), train_y).data\n",
    "        \n",
    "        epoch_test_accuracy = accuracy(model(test_x), test_y)\n",
    "        epoch_test_loss = loss_fn(model(test_x), test_y).data\n",
    "        print('epoch: ', epoch, 'loss： ', round(epoch_loss.item(), 3),\n",
    "                                'accuracy:', round(epoch_accuracy.item(), 3),\n",
    "                                'test_loss： ', round(epoch_test_loss.item(), 3),\n",
    "                                'test_accuracy:', round(epoch_test_accuracy.item(), 3)\n",
    "             )\n",
    "        \n",
    "        train_loss.append(epoch_loss)\n",
    "        train_acc.append(epoch_accuracy)\n",
    "        test_loss.append(epoch_test_loss)\n",
    "        test_acc.append(epoch_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs+1), train_loss, label='train_loss')\n",
    "plt.plot(range(1, epochs+1), test_loss, label='test_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs+1), train_acc, label='train_acc')\n",
    "plt.plot(range(1, epochs+1), test_acc, label='test_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模板代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 创建输入（dataloader）\n",
    "2. 创建模型（model）\n",
    "3  创建损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编写一个fit，输入模型、输入数据（train_dl, test_dl）， 对数据输入在模型上训练，并且返回loss和acc变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch, model, trainloader, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    for x, y in trainloader:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            correct += (y_pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(trainloader.dataset)\n",
    "    epoch_acc = correct / total\n",
    "        \n",
    "        \n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    test_running_loss = 0 \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            test_correct += (y_pred == y).sum().item()\n",
    "            test_total += y.size(0)\n",
    "            test_running_loss += loss.item()\n",
    "    \n",
    "    epoch_test_loss = test_running_loss / len(testloader.dataset)\n",
    "    epoch_test_acc = test_correct / test_total\n",
    "    \n",
    "        \n",
    "    print('epoch: ', epoch, \n",
    "          'loss： ', round(epoch_loss, 3),\n",
    "          'accuracy:', round(epoch_acc, 3),\n",
    "          'test_loss： ', round(epoch_test_loss, 3),\n",
    "          'test_accuracy:', round(epoch_test_acc, 3)\n",
    "             )\n",
    "        \n",
    "    return epoch_loss, epoch_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss, epoch_acc, epoch_test_loss, epoch_test_acc = fit(epoch,\n",
    "                                                                 model,\n",
    "                                                                 train_dl,\n",
    "                                                                 test_dl)\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_acc.append(epoch_acc)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    test_acc.append(epoch_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs+1), train_loss, label='train_loss')\n",
    "plt.plot(range(1, epochs+1), test_loss, label='test_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs+1), train_acc, label='train_acc')\n",
    "plt.plot(range(1, epochs+1), test_acc, label='test_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.2.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
