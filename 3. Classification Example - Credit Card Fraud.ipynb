{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类实例-信用卡欺诈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础知识：逻辑回归与交叉熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 线性回归预测的是一个连续值\n",
    "* 逻辑回归给出的`是`或`否`的回答\n",
    "\n",
    "**Sigmoid函数：** \n",
    "* y = 1 / [1 + e ^ (-x)] （将 (-∞, +∞) 映射到 (0, 1) ）\n",
    "* Sigmoid函数是一个概率分布函数，给定某个输入，将输出为一个概率值\n",
    "\n",
    "**逻辑回归损失函数**\n",
    "* `平方差`所惩罚的是与损失为同一数量级的情形\n",
    "* 对于分类问题，最好使用`交叉熵`损失函数，交叉熵会输出一个更大的“损失”  \n",
    "\n",
    "    交叉熵刻画的是实际输出（概率）与期望输出（概率）的距离，也就是交叉熵的值越小，两个概率分布就越接近。  \n",
    "    假设`概率分布p`为期望输出，`概率分布q`为实际输出，`H(p,q)`为交叉熵，则：`H(p,q) = -Σ[p(x)logq(x)]`  \n",
    "\n",
    "    在Pytorch中，使用`nn.BCELoss()`来计算二元交叉熵损失（在线性回归中，使用`nn.MSELoss()`计算均方差损失）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0      1      2   3   4   5   6     7   8   9   10  11  12   13     14  15\n",
      "0   0  30.83  0.000   0   0   9   0  1.25   0   0   1   1   0  202    0.0  -1\n",
      "1   1  58.67  4.460   0   0   8   1  3.04   0   0   6   1   0   43  560.0  -1\n",
      "2   1  24.50  0.500   0   0   8   1  1.50   0   1   0   1   0  280  824.0  -1\n",
      "3   0  27.83  1.540   0   0   9   0  3.75   0   0   5   0   0  100    3.0  -1\n",
      "4   0  20.17  5.625   0   0   9   0  1.71   0   1   0   1   2  120    0.0  -1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 653 entries, 0 to 652\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       653 non-null    int64  \n",
      " 1   1       653 non-null    float64\n",
      " 2   2       653 non-null    float64\n",
      " 3   3       653 non-null    int64  \n",
      " 4   4       653 non-null    int64  \n",
      " 5   5       653 non-null    int64  \n",
      " 6   6       653 non-null    int64  \n",
      " 7   7       653 non-null    float64\n",
      " 8   8       653 non-null    int64  \n",
      " 9   9       653 non-null    int64  \n",
      " 10  10      653 non-null    int64  \n",
      " 11  11      653 non-null    int64  \n",
      " 12  12      653 non-null    int64  \n",
      " 13  13      653 non-null    int64  \n",
      " 14  14      653 non-null    float64\n",
      " 15  15      653 non-null    int64  \n",
      "dtypes: float64(4), int64(12)\n",
      "memory usage: 81.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('./dataset/Credit.csv', header=None)\n",
    "print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0      1      2   3   4   5   6     7   8   9   10  11  12   13     14\n",
      "0   0  30.83  0.000   0   0   9   0  1.25   0   0   1   1   0  202    0.0\n",
      "1   1  58.67  4.460   0   0   8   1  3.04   0   0   6   1   0   43  560.0\n",
      "2   1  24.50  0.500   0   0   8   1  1.50   0   1   0   1   0  280  824.0\n",
      "3   0  27.83  1.540   0   0   9   0  3.75   0   0   5   0   0  100    3.0\n",
      "4   0  20.17  5.625   0   0   9   0  1.71   0   1   0   1   2  120    0.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 653 entries, 0 to 652\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       653 non-null    int64  \n",
      " 1   1       653 non-null    float64\n",
      " 2   2       653 non-null    float64\n",
      " 3   3       653 non-null    int64  \n",
      " 4   4       653 non-null    int64  \n",
      " 5   5       653 non-null    int64  \n",
      " 6   6       653 non-null    int64  \n",
      " 7   7       653 non-null    float64\n",
      " 8   8       653 non-null    int64  \n",
      " 9   9       653 non-null    int64  \n",
      " 10  10      653 non-null    int64  \n",
      " 11  11      653 non-null    int64  \n",
      " 12  12      653 non-null    int64  \n",
      " 13  13      653 non-null    int64  \n",
      " 14  14      653 non-null    float64\n",
      "dtypes: float64(4), int64(11)\n",
      "memory usage: 76.6 KB\n",
      "None\n",
      "[-1  1]\n",
      "[0 1]\n",
      "15\n",
      "1    357\n",
      "0    296\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into X and y\n",
    "X = data.iloc[:, :-1] # 所有的行，前15列为特征\n",
    "print(X.head())\n",
    "print(X.info())\n",
    "Y = data.iloc[:, -1]  # 所有的行，最后一列为标签\n",
    "print(Y.unique())\n",
    "Y = data.iloc[:, -1].replace(-1, 0)  # 将-1转换为0，则标签全部转换为0和1\n",
    "# 或者使用下面的方法建立映射\n",
    "# Y = data.iloc[:, -1].map({-1: 0, 1: 1})\n",
    "print(Y.unique())\n",
    "print(Y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32\n",
      "torch.Size([653, 15]) torch.Size([653, 1])\n"
     ]
    }
   ],
   "source": [
    "# Convert the data to PyTorch tensors\n",
    "X = torch.from_numpy(X.values).float()  # 或者使用.type(torch.FloatTensor)或.type(torch.float32)\n",
    "Y = torch.from_numpy(Y.values.reshape(-1, 1)).float()\n",
    "print(X.dtype, Y.dtype)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (1): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = nn.Sequential(  # 定义一个序列模型，Sequential可以将多个层顺序地链接在一起\n",
    "                    nn.Linear(15, 1),   # 第一层为线性层，输入特征为15，输出特征为1\n",
    "                    nn.Sigmoid()        # 第二层为Sigmoid激活函数\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "loss_fn = nn.BCELoss() # 二分类交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.0001)  # Adam优化器\n",
    "# Adam优化器:自适应矩估计，可以考虑前几次的梯度，不仅考虑当前的梯度，还考虑之前的梯度\n",
    "# SGD优化器:随机梯度下降，不会考虑前几次的梯度，只考虑当前的梯度\n",
    "# opt = torch.optim.SGD(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 小批量训练\n",
    "# Define the batch size\n",
    "batches = 16\n",
    "num_of_batches = 653//16 # //表示整除\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch in range(num_of_batches):     # 按照批次进行训练\n",
    "        start = batch*batches               # 每个批次的起始索引\n",
    "        end = start + batches               # 每个批次的结束索引\n",
    "        x = X[start: end]\n",
    "        y = Y[start: end]\n",
    "        # Forward pass\n",
    "        y_pred = model(x)\n",
    "        # Compute loss: BCELoss expects the target to be between 0 and 1\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        # Gradient reset\n",
    "        opt.zero_grad()\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update the gradients\n",
    "        opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-1.3642e-01, -4.1447e-03, -2.2829e-03,  3.2313e-01,  7.2476e-02,\n",
       "                       -1.2334e-02,  1.7850e-01, -1.6634e-01,  2.0218e+00,  4.6058e-01,\n",
       "                       -1.6475e-01,  2.3076e-02, -2.5798e-02,  1.1224e-03, -3.3326e-04]])),\n",
       "             ('0.bias', tensor([-0.2449]))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看模型的参数\n",
    "model.state_dict() # sigmoid(w1*x1 + w2*x2 + ... + w15*x15 + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.83001531393569%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model: 计算准确率\n",
    "accuracy = ((model(X).data.numpy() > 0.5).astype(int) == Y.numpy()).mean()\n",
    "# model(X).data.numpy() > 0.5: 将模型的输出值大于0.5的转换为1，小于0.5的转换为0\n",
    "# .astype(int): 将布尔值转换为整数\n",
    "# == Y.numpy(): 将转换后的值与真实值进行比较\n",
    "# .mean(): 计算均值，即准确率\n",
    "print(str(accuracy * 100) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.2.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
