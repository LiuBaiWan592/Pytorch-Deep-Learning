{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模板整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from PIL import Image   #  pip install pillow\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(232),                       # 将图片缩放到232\n",
    "    transforms.RandomCrop(224),                   # 随机裁剪224\n",
    "    transforms.RandomHorizontalFlip(),            # 随机水平翻转，默认概率为0.5\n",
    "    transforms.RandomRotation(0.2),               # 随机旋转0.2弧度\n",
    "    transforms.ColorJitter(brightness=0.5),       # 亮度调整\n",
    "    transforms.ColorJitter(contrast=0.5),         # 对比度调整\n",
    "    transforms.ToTensor(),                        # 将图片转换为张量\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                        std=[0.5, 0.5, 0.5])      # 将图片的每个通道的像素值减去均值，再除以标准差，使像素值均值为0，标准差为1\n",
    "])\n",
    "\n",
    "# 测试集不需要数据增强\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                # 将图片缩放到224, 224（VGG卷积深度较深，输入图片大小不能过小）\n",
    "    transforms.ToTensor(),                        # 将图片转换为张量\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                        std=[0.5, 0.5, 0.5])      # 将图片的每个通道的像素值减去均值，再除以标准差，使像素值均值为0，标准差为1\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练集和测试集的图片\n",
    "train_ds = torchvision.datasets.ImageFolder(\n",
    "                                            train_dir,\n",
    "                                            transform=train_transform\n",
    ")\n",
    "test_ds = torchvision.datasets.ImageFolder(\n",
    "                                            test_dir,\n",
    "                                            transform=test_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 16\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "                                       train_ds,\n",
    "                                       batch_size=BATCHSIZE,\n",
    "                                       shuffle=True\n",
    ")\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "                                       test_ds,\n",
    "                                       batch_size=BATCHSIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True           # 开启CUDNN加速\n",
    "BATCHSIZE = 32\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "                                       train_ds,\n",
    "                                       batch_size=BATCHSIZE,\n",
    "                                       shuffle=True,\n",
    "                                       num_workers=2,           # 使用2个进程加载数据\n",
    "                                       prefetch_factor=2,       # 预取的批次数量，默认为2\n",
    "                                       pin_memory=True,         # 将数据固定在GPU内存中，加速数据传输\n",
    "                                       persistent_workers=True, # 持久化加载器，在数据加载器关闭后，仍然保持进程运行，提高数据加载效率\n",
    "\n",
    ")\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "                                       test_ds,\n",
    "                                       batch_size=BATCHSIZE,\n",
    "                                       num_workers=2,           # 使用2个进程加载数据\n",
    "                                       prefetch_factor=2,       # 预取的批次数量，默认为2\n",
    "                                       pin_memory=True,         # 将数据固定在GPU内存中，加速数据传输\n",
    "                                       persistent_workers=True, # 持久化加载器，在数据加载器关闭后，仍然保持进程运行，提高数据加载效率\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数整理\n",
    "model = model\n",
    "learn_rate = 0.00001\n",
    "epochs = 50\n",
    "train_dl = train_dl\n",
    "test_dl = test_dl\n",
    "\n",
    "# 训练前准备，定义模型、损失函数、优化器\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 判断是否有GPU，如果有则使用GPU，否则使用CPU\n",
    "model.to(device) # 将已实例化的模型移动到GPU上\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()  # 损失函数，交叉熵损失函数，使用未激活的输出作为输入，内置了softmax函数为激活函数，输出为每个类别的概率\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learn_rate) # 优化器，Adam优化器\n",
    "\n",
    "# 通用训练模板，输入模型、训练数据、测试数据，返回loss和acc变化\n",
    "# 训练函数\n",
    "def train(train_dl, model, loss_fn, opt):\n",
    "    size = len(train_dl.dataset) # 获取数据集的大小\n",
    "    num_batches = len(train_dl) # 获取数据集的批次数量\n",
    "\n",
    "    train_loss = 0.0 # 训练集损失\n",
    "    train_acc = 0.0 # 训练集准确率\n",
    "\n",
    "    for x, y in train_dl: # 遍历数据集\n",
    "        y = torch.tensor(y, dtype=torch.long) # 将标签转换为long类型\n",
    "        x, y = x.to(device), y.to(device) # 将数据移动到GPU上\n",
    "\n",
    "        pred = model(x) # 前向传播\n",
    "        loss = loss_fn(pred, y) # 计算损失\n",
    "\n",
    "        opt.zero_grad() # 梯度清零\n",
    "        loss.backward() # 反向传播\n",
    "        opt.step() # 更新参数\n",
    "\n",
    "        with torch.no_grad(): # 不计算梯度\n",
    "            train_loss += loss.item() # 计算损失\n",
    "            train_acc += (pred.argmax(dim=1) == y).type(torch.float).sum().item() # 计算准确率\n",
    "\n",
    "    train_loss /= num_batches # 计算平均损失\n",
    "    train_acc /= size # 计算平均准确率\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "# 测试函数\n",
    "def test(test_dl, model, loss_fn):\n",
    "    size = len(test_dl.dataset) # 获取数据集的大小\n",
    "    num_batches = len(test_dl) # 获取数据集的批次数量\n",
    "\n",
    "    test_loss = 0.0 # 测试集损失\n",
    "    test_acc = 0.0 # 测试集准确率\n",
    "\n",
    "    with torch.no_grad(): # 不计算梯度\n",
    "        for x, y in test_dl: # 遍历数据集\n",
    "            y = torch.tensor(y, dtype=torch.long) # 将标签转换为long类型\n",
    "            x, y = x.to(device), y.to(device) # 将数据移动到GPU上\n",
    "\n",
    "            pred = model(x) # 前向传播\n",
    "            loss = loss_fn(pred, y) # 计算损失\n",
    "            test_loss += loss.item() # 计算损失\n",
    "            test_acc += (pred.argmax(dim=1) == y).type(torch.float).sum().item() # 计算准确率\n",
    "\n",
    "    test_loss /= num_batches # 计算平均损失\n",
    "    test_acc /= size # 计算平均准确率\n",
    "\n",
    "    return test_loss, test_acc\n",
    "\n",
    "# 训练函数\n",
    "def fit(epochs, model, train_dl, test_dl, loss_fn, opt):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "\n",
    "    print_template = 'Epoch: {}, Train Loss: {:.4f}, Train Acc: {:.2f}%, Test Loss: {:.4f}, Test Acc: {:.2f}%'\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train() # 设置模型为训练模式，启用dropout层\n",
    "        epoch_train_loss, epoch_train_acc = train(train_dl, model, loss_fn, opt)\n",
    "        model.eval() # 设置模型为评估预测模式，禁用dropout层\n",
    "        epoch_test_loss, epoch_test_acc = test(test_dl, model, loss_fn)\n",
    "\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        train_acc.append(epoch_train_acc)\n",
    "        test_loss.append(epoch_test_loss)\n",
    "        test_acc.append(epoch_test_acc)\n",
    "\n",
    "        print(print_template.format(epoch, epoch_train_loss, epoch_train_acc * 100, epoch_test_loss, epoch_test_acc * 100))\n",
    "\n",
    "    return train_loss, train_acc, test_loss, test_acc\n",
    "\n",
    "# 训练\n",
    "train_loss, train_acc, test_loss, test_acc = fit(epochs, model, train_dl, test_dl, loss_fn, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs+1), train_loss, label='train_loss')\n",
    "plt.plot(range(1, epochs+1), test_loss, label='test_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs+1), train_acc, label='train_acc')\n",
    "plt.plot(range(1, epochs+1), test_acc, label='test_acc')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.2.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
