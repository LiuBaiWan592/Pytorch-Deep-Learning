{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模板整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from PIL import Image   #  pip install pillow\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(232),                       # 将图片缩放到232\n",
    "    transforms.RandomCrop(224),                   # 随机裁剪224\n",
    "    transforms.RandomHorizontalFlip(),            # 随机水平翻转，默认概率为0.5\n",
    "    transforms.RandomRotation(0.2),               # 随机旋转0.2弧度\n",
    "    transforms.ColorJitter(brightness=0.5),       # 亮度调整\n",
    "    transforms.ColorJitter(contrast=0.5),         # 对比度调整\n",
    "    transforms.ToTensor(),                        # 将图片转换为张量\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                        std=[0.5, 0.5, 0.5])      # 将图片的每个通道的像素值减去均值，再除以标准差，使像素值均值为0，标准差为1\n",
    "])\n",
    "\n",
    "# 测试集不需要数据增强\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                # 将图片缩放到224, 224（VGG卷积深度较深，输入图片大小不能过小）\n",
    "    transforms.ToTensor(),                        # 将图片转换为张量\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                        std=[0.5, 0.5, 0.5])      # 将图片的每个通道的像素值减去均值，再除以标准差，使像素值均值为0，标准差为1\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练集和测试集的图片\n",
    "train_ds = torchvision.datasets.ImageFolder(\n",
    "                                            train_dir,\n",
    "                                            transform=train_transform\n",
    ")\n",
    "test_ds = torchvision.datasets.ImageFolder(\n",
    "                                            test_dir,\n",
    "                                            transform=test_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据集类\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, images, lables):\n",
    "        self.images = images\n",
    "        self.lables = lables\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.images[index], self.lables[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 16\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "                                       train_ds,\n",
    "                                       batch_size=BATCHSIZE,\n",
    "                                       shuffle=True\n",
    ")\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "                                       test_ds,\n",
    "                                       batch_size=BATCHSIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True           # 开启CUDNN加速\n",
    "BATCHSIZE = 32\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "                                       train_ds,\n",
    "                                       batch_size=BATCHSIZE,\n",
    "                                       shuffle=True,\n",
    "                                       num_workers=2,           # 使用2个进程加载数据\n",
    "                                       prefetch_factor=2,       # 预取的批次数量，默认为2\n",
    "                                       pin_memory=True,         # 将数据固定在GPU内存中，加速数据传输\n",
    "                                       persistent_workers=True, # 持久化加载器，在数据加载器关闭后，仍然保持进程运行，提高数据加载效率\n",
    "\n",
    ")\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "                                       test_ds,\n",
    "                                       batch_size=BATCHSIZE,\n",
    "                                       num_workers=2,           # 使用2个进程加载数据\n",
    "                                       prefetch_factor=2,       # 预取的批次数量，默认为2\n",
    "                                       pin_memory=True,         # 将数据固定在GPU内存中，加速数据传输\n",
    "                                       persistent_workers=True, # 持久化加载器，在数据加载器关闭后，仍然保持进程运行，提高数据加载效率\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数整理\n",
    "model = model\n",
    "learn_rate = 0.00001\n",
    "epochs = 50\n",
    "train_dl = train_dl\n",
    "test_dl = test_dl\n",
    "\n",
    "# 训练前准备，定义模型、损失函数、优化器\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 判断是否有GPU，如果有则使用GPU，否则使用CPU\n",
    "model.to(device) # 将已实例化的模型移动到GPU上\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()  # 损失函数，交叉熵损失函数，使用未激活的输出作为输入，内置了softmax函数为激活函数，输出为每个类别的概率\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learn_rate) # 优化器，Adam优化器\n",
    "\n",
    "# 通用训练模板，输入模型、训练数据、测试数据，返回loss和acc变化\n",
    "# 训练函数\n",
    "def train(train_dl, model, loss_fn, opt):\n",
    "    size = len(train_dl.dataset) # 获取数据集的大小\n",
    "    num_batches = len(train_dl) # 获取数据集的批次数量\n",
    "\n",
    "    train_loss = 0.0 # 训练集损失\n",
    "    train_acc = 0.0 # 训练集准确率\n",
    "\n",
    "    for x, y in train_dl: # 遍历数据集\n",
    "        y = y.long()      # 将标签转换为long类型\n",
    "        x, y = x.to(device), y.to(device) # 将数据移动到GPU上\n",
    "\n",
    "        pred = model(x) # 前向传播\n",
    "        loss = loss_fn(pred, y) # 计算损失\n",
    "\n",
    "        opt.zero_grad() # 梯度清零\n",
    "        loss.backward() # 反向传播\n",
    "        opt.step() # 更新参数\n",
    "\n",
    "        with torch.no_grad(): # 不计算梯度\n",
    "            train_loss += loss.item() # 计算损失\n",
    "            train_acc += (pred.argmax(dim=1) == y).type(torch.float).sum().item() # 计算准确率\n",
    "\n",
    "    train_loss /= num_batches # 计算平均损失\n",
    "    train_acc /= size # 计算平均准确率\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "# 测试函数\n",
    "def test(test_dl, model, loss_fn):\n",
    "    size = len(test_dl.dataset) # 获取数据集的大小\n",
    "    num_batches = len(test_dl) # 获取数据集的批次数量\n",
    "\n",
    "    test_loss = 0.0 # 测试集损失\n",
    "    test_acc = 0.0 # 测试集准确率\n",
    "\n",
    "    with torch.no_grad(): # 不计算梯度\n",
    "        for x, y in test_dl:  # 遍历数据集\n",
    "            y = y.long()      # 将标签转换为long类型\n",
    "            x, y = x.to(device), y.to(device) # 将数据移动到GPU上\n",
    "\n",
    "            pred = model(x) # 前向传播\n",
    "            loss = loss_fn(pred, y) # 计算损失\n",
    "            test_loss += loss.item() # 计算损失\n",
    "            test_acc += (pred.argmax(dim=1) == y).type(torch.float).sum().item() # 计算准确率\n",
    "\n",
    "    test_loss /= num_batches # 计算平均损失\n",
    "    test_acc /= size # 计算平均准确率\n",
    "\n",
    "    return test_loss, test_acc\n",
    "\n",
    "# 训练函数\n",
    "def fit(epochs, model, train_dl, test_dl, loss_fn, opt):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "\n",
    "    print_template = 'Epoch: {}, Train Loss: {:.4f}, Train Acc: {:.2f}%, Test Loss: {:.4f}, Test Acc: {:.2f}%'\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train() # 设置模型为训练模式，启用dropout层\n",
    "        epoch_train_loss, epoch_train_acc = train(train_dl, model, loss_fn, opt)\n",
    "        model.eval() # 设置模型为评估预测模式，禁用dropout层\n",
    "        epoch_test_loss, epoch_test_acc = test(test_dl, model, loss_fn)\n",
    "\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        train_acc.append(epoch_train_acc)\n",
    "        test_loss.append(epoch_test_loss)\n",
    "        test_acc.append(epoch_test_acc)\n",
    "\n",
    "        print(print_template.format(epoch, epoch_train_loss, epoch_train_acc * 100, epoch_test_loss, epoch_test_acc * 100))\n",
    "\n",
    "    return train_loss, train_acc, test_loss, test_acc\n",
    "\n",
    "# 训练\n",
    "train_loss, train_acc, test_loss, test_acc = fit(epochs, model, train_dl, test_dl, loss_fn, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 带有学习率调整器的训练模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数整理\n",
    "model = model\n",
    "learn_rate = 0.00001\n",
    "epochs = 50\n",
    "train_dl = train_dl\n",
    "test_dl = test_dl\n",
    "\n",
    "# 训练前准备，定义模型、损失函数、优化器\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 判断是否有GPU，如果有则使用GPU，否则使用CPU\n",
    "model.to(device) # 将已实例化的模型移动到GPU上\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()  # 损失函数，交叉熵损失函数，使用未激活的输出作为输入，内置了softmax函数为激活函数，输出为每个类别的概率\n",
    "opt = torch.optim.Adam(model.fc.parameters(), lr=learn_rate) # 优化器，Adam优化器\n",
    "\n",
    "# 学习率调整器\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# # 手动调整学习率\n",
    "# for param_group in opt.param_groups:\n",
    "#     print(param_group['lr'])\n",
    "#     param_group['lr'] *= 0.9\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(opt, step_size=10, gamma=0.5) # 每隔10个epoch，学习率衰减为原来的0.5倍\n",
    "\n",
    "# lr_scheduler.MultiStepLR(opt, milestones=[5, 10, 15, 20], gamma=0.5) # 每隔5个epoch，学习率衰减为原来的0.1倍\n",
    "# lr_scheduler.ExponentialLR(opt, gamma=0.5) # 每个epoch，学习率衰减为原来的0.5倍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.9353, Train Acc: 67.67%, Test Loss: 0.6302, Test Acc: 84.89%\n",
      "Epoch: 1, Train Loss: 0.4842, Train Acc: 88.78%, Test Loss: 0.3764, Test Acc: 93.78%\n",
      "Epoch: 2, Train Loss: 0.3630, Train Acc: 91.67%, Test Loss: 0.3267, Test Acc: 90.22%\n",
      "Epoch: 3, Train Loss: 0.2960, Train Acc: 93.22%, Test Loss: 0.2727, Test Acc: 93.78%\n",
      "Epoch: 4, Train Loss: 0.2890, Train Acc: 94.11%, Test Loss: 0.2334, Test Acc: 94.22%\n",
      "Epoch: 5, Train Loss: 0.2261, Train Acc: 94.89%, Test Loss: 0.2309, Test Acc: 95.11%\n",
      "Epoch: 6, Train Loss: 0.2116, Train Acc: 95.00%, Test Loss: 0.2037, Test Acc: 93.78%\n",
      "Epoch: 7, Train Loss: 0.2168, Train Acc: 93.56%, Test Loss: 0.2139, Test Acc: 93.33%\n",
      "Epoch: 8, Train Loss: 0.1965, Train Acc: 95.78%, Test Loss: 0.1864, Test Acc: 94.67%\n",
      "Epoch: 9, Train Loss: 0.1601, Train Acc: 95.78%, Test Loss: 0.1887, Test Acc: 94.22%\n",
      "Epoch: 10, Train Loss: 0.1673, Train Acc: 95.44%, Test Loss: 0.1711, Test Acc: 94.22%\n",
      "Epoch: 11, Train Loss: 0.1528, Train Acc: 96.44%, Test Loss: 0.1768, Test Acc: 92.89%\n",
      "Epoch: 12, Train Loss: 0.1688, Train Acc: 95.67%, Test Loss: 0.1759, Test Acc: 94.22%\n",
      "Epoch: 13, Train Loss: 0.1549, Train Acc: 96.00%, Test Loss: 0.1761, Test Acc: 93.33%\n",
      "Epoch: 14, Train Loss: 0.1887, Train Acc: 95.56%, Test Loss: 0.1668, Test Acc: 94.67%\n",
      "Epoch: 15, Train Loss: 0.1443, Train Acc: 96.11%, Test Loss: 0.1735, Test Acc: 93.78%\n",
      "Epoch: 16, Train Loss: 0.1494, Train Acc: 96.56%, Test Loss: 0.1577, Test Acc: 95.11%\n",
      "Epoch: 17, Train Loss: 0.1592, Train Acc: 95.44%, Test Loss: 0.1659, Test Acc: 94.22%\n",
      "Epoch: 18, Train Loss: 0.1355, Train Acc: 96.56%, Test Loss: 0.1694, Test Acc: 95.11%\n",
      "Epoch: 19, Train Loss: 0.1284, Train Acc: 97.00%, Test Loss: 0.1494, Test Acc: 95.11%\n",
      "Epoch: 20, Train Loss: 0.1135, Train Acc: 96.89%, Test Loss: 0.1606, Test Acc: 94.67%\n",
      "Epoch: 21, Train Loss: 0.1290, Train Acc: 96.78%, Test Loss: 0.1591, Test Acc: 94.22%\n",
      "Epoch: 22, Train Loss: 0.1434, Train Acc: 96.22%, Test Loss: 0.1637, Test Acc: 95.56%\n",
      "Epoch: 23, Train Loss: 0.1199, Train Acc: 96.67%, Test Loss: 0.1514, Test Acc: 94.67%\n",
      "Epoch: 24, Train Loss: 0.1294, Train Acc: 96.33%, Test Loss: 0.1575, Test Acc: 94.22%\n",
      "Epoch: 25, Train Loss: 0.1252, Train Acc: 97.22%, Test Loss: 0.1597, Test Acc: 95.56%\n",
      "Epoch: 26, Train Loss: 0.1251, Train Acc: 96.22%, Test Loss: 0.1599, Test Acc: 94.67%\n",
      "Epoch: 27, Train Loss: 0.1053, Train Acc: 97.78%, Test Loss: 0.1464, Test Acc: 94.67%\n",
      "Epoch: 28, Train Loss: 0.1117, Train Acc: 97.67%, Test Loss: 0.1579, Test Acc: 94.67%\n",
      "Epoch: 29, Train Loss: 0.1140, Train Acc: 97.44%, Test Loss: 0.1634, Test Acc: 94.22%\n"
     ]
    }
   ],
   "source": [
    "# 通用训练模板，输入模型、训练数据、测试数据，返回loss和acc变化\n",
    "# 训练函数\n",
    "def train(train_dl, model, loss_fn, opt, exp_lr_scheduler):\n",
    "    size = len(train_dl.dataset) # 获取数据集的大小\n",
    "    num_batches = len(train_dl) # 获取数据集的批次数量\n",
    "\n",
    "    train_loss = 0.0 # 训练集损失\n",
    "    train_acc = 0.0 # 训练集准确率\n",
    "\n",
    "    for x, y in train_dl: # 遍历数据集\n",
    "        x, y = x.to(device), y.to(device) # 将数据移动到GPU上\n",
    "\n",
    "        pred = model(x) # 前向传播\n",
    "        loss = loss_fn(pred, y) # 计算损失\n",
    "\n",
    "        opt.zero_grad() # 梯度清零\n",
    "        loss.backward() # 反向传播\n",
    "        opt.step() # 更新参数\n",
    "\n",
    "        with torch.no_grad(): # 不计算梯度\n",
    "            train_loss += loss.item() # 计算损失\n",
    "            train_acc += (pred.argmax(dim=1) == y).type(torch.float).sum().item() # 计算准确率\n",
    "\n",
    "    exp_lr_scheduler.step() # 学习率调整\n",
    "    train_loss /= num_batches # 计算平均损失\n",
    "    train_acc /= size # 计算平均准确率\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "# 测试函数\n",
    "def test(test_dl, model, loss_fn):\n",
    "    size = len(test_dl.dataset) # 获取数据集的大小\n",
    "    num_batches = len(test_dl) # 获取数据集的批次数量\n",
    "\n",
    "    test_loss = 0.0 # 测试集损失\n",
    "    test_acc = 0.0 # 测试集准确率\n",
    "\n",
    "    with torch.no_grad(): # 不计算梯度\n",
    "        for x, y in test_dl: # 遍历数据集\n",
    "            x, y = x.to(device), y.to(device) # 将数据移动到GPU上\n",
    "\n",
    "            pred = model(x) # 前向传播\n",
    "            loss = loss_fn(pred, y) # 计算损失\n",
    "            test_loss += loss.item() # 计算损失\n",
    "            test_acc += (pred.argmax(dim=1) == y).type(torch.float).sum().item() # 计算准确率\n",
    "\n",
    "    test_loss /= num_batches # 计算平均损失\n",
    "    test_acc /= size # 计算平均准确率\n",
    "\n",
    "    return test_loss, test_acc\n",
    "\n",
    "# 训练函数\n",
    "def fit(epochs, model, train_dl, test_dl, loss_fn, opt, exp_lr_scheduler):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "\n",
    "    print_template = 'Epoch: {}, Train Loss: {:.4f}, Train Acc: {:.2f}%, Test Loss: {:.4f}, Test Acc: {:.2f}%'\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train() # 设置模型为训练模式，启用dropout层\n",
    "        epoch_train_loss, epoch_train_acc = train(train_dl, model, loss_fn, opt, exp_lr_scheduler)\n",
    "        model.eval() # 设置模型为评估预测模式，禁用dropout层\n",
    "        epoch_test_loss, epoch_test_acc = test(test_dl, model, loss_fn)\n",
    "\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        train_acc.append(epoch_train_acc)\n",
    "        test_loss.append(epoch_test_loss)\n",
    "        test_acc.append(epoch_test_acc)\n",
    "\n",
    "        print(print_template.format(epoch, epoch_train_loss, epoch_train_acc * 100, epoch_test_loss, epoch_test_acc * 100))\n",
    "\n",
    "    return train_loss, train_acc, test_loss, test_acc\n",
    "\n",
    "# 训练\n",
    "train_loss, train_acc, test_loss, test_acc = fit(epochs, model, train_dl, test_dl, loss_fn, opt, exp_lr_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs+1), train_loss, label='train_loss')\n",
    "plt.plot(range(1, epochs+1), test_loss, label='test_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs+1), train_acc, label='train_acc')\n",
    "plt.plot(range(1, epochs+1), test_acc, label='test_acc')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.2.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
