{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二分类问题-HR数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>part</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years   part  \\\n",
       "0                   3              0     1                      0  sales   \n",
       "1                   6              0     1                      0  sales   \n",
       "2                   4              0     1                      0  sales   \n",
       "3                   5              0     1                      0  sales   \n",
       "4                   3              0     1                      0  sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "data = pd.read_csv('./dataset/HR.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   satisfaction_level     14999 non-null  float64\n",
      " 1   last_evaluation        14999 non-null  float64\n",
      " 2   number_project         14999 non-null  int64  \n",
      " 3   average_montly_hours   14999 non-null  int64  \n",
      " 4   time_spend_company     14999 non-null  int64  \n",
      " 5   Work_accident          14999 non-null  int64  \n",
      " 6   left                   14999 non-null  int64  \n",
      " 7   promotion_last_5years  14999 non-null  int64  \n",
      " 8   part                   14999 non-null  object \n",
      " 9   salary                 14999 non-null  object \n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "['sales' 'accounting' 'hr' 'technical' 'support' 'management' 'IT'\n",
      " 'product_mng' 'marketing' 'RandD']\n",
      "['low' 'medium' 'high']\n"
     ]
    }
   ],
   "source": [
    "# 数据基本信息\n",
    "print(data.info())\n",
    "print(data.part.unique())\n",
    "print(data.salary.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>IT</th>\n",
       "      <th>RandD</th>\n",
       "      <th>...</th>\n",
       "      <th>hr</th>\n",
       "      <th>management</th>\n",
       "      <th>marketing</th>\n",
       "      <th>product_mng</th>\n",
       "      <th>sales</th>\n",
       "      <th>support</th>\n",
       "      <th>technical</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years  IT  RandD  \\\n",
       "0                   3              0     1                      0   0      0   \n",
       "1                   6              0     1                      0   0      0   \n",
       "2                   4              0     1                      0   0      0   \n",
       "3                   5              0     1                      0   0      0   \n",
       "4                   3              0     1                      0   0      0   \n",
       "\n",
       "   ...  hr  management  marketing  product_mng  sales  support  technical  \\\n",
       "0  ...   0           0          0            0      1        0          0   \n",
       "1  ...   0           0          0            0      1        0          0   \n",
       "2  ...   0           0          0            0      1        0          0   \n",
       "3  ...   0           0          0            0      1        0          0   \n",
       "4  ...   0           0          0            0      1        0          0   \n",
       "\n",
       "   high  low  medium  \n",
       "0     0    1       0  \n",
       "1     0    0       1  \n",
       "2     0    0       1  \n",
       "3     0    1       0  \n",
       "4     0    1       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据预处理\n",
    "# 简单的数据分析\n",
    "# data.groupby(['salary', 'part']).size()\n",
    "# .get_dummies()方法可以将分类数据转换为one-hot编码\n",
    "data = data.join(pd.get_dummies(data.part).astype(int)).join(pd.get_dummies(data.salary).astype(int))\n",
    "# 删除原来的分类数据\n",
    "data.drop(columns=['part', 'salary'], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   satisfaction_level     14999 non-null  float64\n",
      " 1   last_evaluation        14999 non-null  float64\n",
      " 2   number_project         14999 non-null  int64  \n",
      " 3   average_montly_hours   14999 non-null  int64  \n",
      " 4   time_spend_company     14999 non-null  int64  \n",
      " 5   Work_accident          14999 non-null  int64  \n",
      " 6   left                   14999 non-null  int64  \n",
      " 7   promotion_last_5years  14999 non-null  int64  \n",
      " 8   IT                     14999 non-null  int32  \n",
      " 9   RandD                  14999 non-null  int32  \n",
      " 10  accounting             14999 non-null  int32  \n",
      " 11  hr                     14999 non-null  int32  \n",
      " 12  management             14999 non-null  int32  \n",
      " 13  marketing              14999 non-null  int32  \n",
      " 14  product_mng            14999 non-null  int32  \n",
      " 15  sales                  14999 non-null  int32  \n",
      " 16  support                14999 non-null  int32  \n",
      " 17  technical              14999 non-null  int32  \n",
      " 18  high                   14999 non-null  int32  \n",
      " 19  low                    14999 non-null  int32  \n",
      " 20  medium                 14999 non-null  int32  \n",
      "dtypes: float64(2), int32(13), int64(6)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left\n",
      "0    11428\n",
      "1     3571\n",
      "Name: count, dtype: int64\n",
      "0.7619174611640777\n"
     ]
    }
   ],
   "source": [
    "# 查看离职率\n",
    "print(data.left.value_counts())\n",
    "# 全部预测为不离职\n",
    "print(data.left.value_counts()[0] / data.left.value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14999, 1])\n"
     ]
    }
   ],
   "source": [
    "# 处理结果数据\n",
    "Y_data = data.left.values.reshape(-1, 1)\n",
    "Y = torch.from_numpy(Y_data).type(torch.FloatTensor)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14999, 20])\n"
     ]
    }
   ],
   "source": [
    "# 处理特征数据\n",
    "# 使用列表推导式，获取除了'left'列之外的所有列\n",
    "# [c for c in data.columns if c != 'left']\n",
    "# 使用.values方法，将DataFrame转换为numpy数组\n",
    "X_data = data[[c for c in data.columns if c != 'left']].values\n",
    "X = torch.from_numpy(X_data).type(torch.FloatTensor)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import nn\n",
    "# # 自定义模型：逻辑回归模型\n",
    "# class Logistic(nn.Module):  # 继承nn.Module\n",
    "#     def __init__(self):     # 初始化所有的层\n",
    "#         super().__init__()  # 继承父类中所有的属性和方法\n",
    "#         self.lin_1 = nn.Linear(20, 64)  # 定义第一层线性层，输入维度为20，输出维度为64\n",
    "#         self.lin_2 = nn.Linear(64, 64)  # 定义第二层线性层，输入维度为64，输出维度为64\n",
    "#         self.lin_3 = nn.Linear(64, 1)   # 定义第三层线性层，输入维度为64，输出维度为1\n",
    "#         self.activate = nn.ReLU()       # 定义ReLU激活函数\n",
    "#         self.sigmoid = nn.Sigmoid()     # 定义Sigmoid激活函数\n",
    "#     def forward(self, input):   # 前向传播函数，定义模型的运算过程，覆盖父类中的forward方法\n",
    "#         x = self.lin_1(input)   # 将输入数据传入第一层线性层\n",
    "#         x = self.activate(x)    # ReLU激活函数\n",
    "#         x = self.lin_2(x)       # 将激活后的数据传入第二层线性层\n",
    "#         x = self.activate(x)    # ReLU激活函数\n",
    "#         x = self.lin_3(x)       # 将激活后的数据传入第三层线性层\n",
    "#         x = self.sigmoid(x)     # Sigmoid激活函数\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型改写\n",
    "from torch import nn\n",
    "import torch.nn.functional as F # 函数式API，调用方便使代码更简洁\n",
    "class Logistic(nn.Module):  # 继承nn.Module\n",
    "    def __init__(self):     # 初始化所有的层\n",
    "        super().__init__()  # 继承父类中所有的属性和方法\n",
    "        self.lin_1 = nn.Linear(20, 64)  # 定义第一层线性层，输入维度为20，输出维度为64\n",
    "        self.lin_2 = nn.Linear(64, 64)  # 定义第二层线性层，输入维度为64，输出维度为64\n",
    "        self.lin_3 = nn.Linear(64, 1)   # 定义第三层线性层，输入维度为64，输出维度为1\n",
    "    def forward(self, input):   # 前向传播函数，定义模型的运算过程，覆盖父类中的forward方法\n",
    "        x = F.relu(self.lin_1(input))   # 将输入数据传入第一层线性层，并使用ReLU激活函数\n",
    "        x = F.relu(self.lin_2(x))       # 将激活后的数据传入第二层线性层，并使用ReLU激活函数\n",
    "        x = F.sigmoid(self.lin_3(x))     # 将激活后的数据传入第三层线性层，并使用Sigmoid激活函数\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Logistic(\n",
      "  (lin_1): Linear(in_features=20, out_features=64, bias=True)\n",
      "  (lin_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (lin_3): Linear(in_features=64, out_features=1, bias=True)\n",
      "), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "# 封装模型和优化器的创建，提高代码复用性\n",
    "lr = 0.0001\n",
    "def get_model():\n",
    "    model = Logistic()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    return model, opt\n",
    "print(get_model())\n",
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割数据集，分批次进行训练\n",
    "batch = 64\n",
    "no_of_batches = len(data)//batch\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 手动分批次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分批次循环训练\n",
    "for epoch in range(epochs):\n",
    "    for i in range(no_of_batches):     # 按照批次进行训练\n",
    "        start = i * batch              # 每个批次的起始索引\n",
    "        end = start + batch            # 每个批次的结束索引\n",
    "        x = X[start: end]\n",
    "        y = Y[start: end]\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(x)\n",
    "        # Compute loss: BCELoss expects the target to be between 0 and 1\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        # Gradient reset\n",
    "        opt.zero_grad()\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update the gradients\n",
    "        opt.step()\n",
    "    with torch.no_grad():\n",
    "        print('epoch:', epoch, '   ', 'loss:', loss_fn(model(X), Y).data.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 使用dataset重构模型训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch有一个抽象的Dataset类。Dataset可以是任何具有__len__函数和__getitem__作为对其进行索引的方法的函数。PyTorch的TensorDataset是一个包装张量的Dataset。通过定义索引的长度和方式，这也为我们提供了沿张量的第一维进行迭代，索引和切片的方法。这将使我们在训练的同一行中更容易访问自变量和因变量。下面将自定义HRDataset类创建为的Dataset的子类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "HRdataset = TensorDataset(X, Y)\n",
    "# print(HRdataset[2: 5])\n",
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(no_of_batches):\n",
    "        x, y = HRdataset[i * batch: i * batch + batch]\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    with torch.no_grad():\n",
    "        print('epoch:', epoch, '   ', 'loss:', loss_fn(model(X), Y).data.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 使用DataLoader重构模型训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch DataLoader负责管理批次，DataLoader从Dataset创建，自动为我们提供每个小批量，使遍历批次变得更容易，无需使用`HRdataset[i * batch: i * batch + batch]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "HRdataset = TensorDataset(X, Y)\n",
    "HRdataloader = DataLoader(HRdataset, batch_size=batch) # batch_size: 每个批次的大小为，shuffle: 是否打乱数据\n",
    "\n",
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for x, y in HRdataloader:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    with torch.no_grad():\n",
    "        print('epoch:', epoch, '   ', 'loss:', loss_fn(model(X), Y).data.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分验证数据集和测试数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**过拟合：** 指模型在训练数据上表现良好，但在验证数据（未知数据）上表现不佳。  \n",
    "**欠拟合：** 指模型在训练数据上表现不佳，在验证数据上表现不佳。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面我们只是试图建立一个合理的训练循环以用于我们的训练数据。实际上，始终还应该具有一个验证集，以识别是否过度拟合。\n",
    "\n",
    "训练数据的乱序（shuffle）对于防止批次与过度拟合之间的相关性很重要。另一方面，无论我们是否乱序验证集，验证损失都是相同的。由于shufle需要额外的开销，因此shuffle验证数据没有任何意义。\n",
    "\n",
    "我们将为验证集使用批大小，该批大小是训练集的两倍。这是因为验证集不需要反向传播，因此占用的内存更少（不需要存储梯度）。我们利用这一优势来使用更大的批量，并更快地计算损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11249, 20) (11249, 1) (3750, 20) (3750, 1)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_data, Y_data) # 划分训练集和测试集\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# 将numpy数组转换为PyTorch张量\n",
    "train_x = torch.from_numpy(train_x).type(torch.FloatTensor)\n",
    "test_x = torch.from_numpy(test_x).type(torch.FloatTensor)\n",
    "train_y = torch.from_numpy(train_y).type(torch.FloatTensor)\n",
    "test_y = torch.from_numpy(test_y).type(torch.FloatTensor)\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     train_x = train_x.to('cuda')\n",
    "#     test_x = test_x.to('cuda')\n",
    "#     train_y = train_y.to('cuda')\n",
    "#     test_y = test_y.to('cuda')\n",
    "#     print('Using GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用PyTorch的TensorDataset和DataLoader将数据集转换为数据加载器\n",
    "train_ds = TensorDataset(train_x, train_y)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch)\n",
    "\n",
    "valid_ds = TensorDataset(test_x, test_y)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 准确率计算函数，用于计算预测值和真实值之间的准确率\n",
    "def accuracy(y_pred, y_true):\n",
    "    # 将预测值大于0.5的值转换为1，其余的转换为0\n",
    "    y_pred = (y_pred>0.5).type(torch.IntTensor)\n",
    "    # y_pred = (y_pred>0.5).type(torch.IntTensor).to('cuda')\n",
    "    # 计算预测值和真实值相等的数量，并转换为浮点数\n",
    "    return (y_pred == y_true).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0     loss: 0.55     test_loss: 0.567\n",
      "epoch: 1     loss: 0.548     test_loss: 0.565\n",
      "epoch: 2     loss: 0.545     test_loss: 0.562\n",
      "epoch: 3     loss: 0.542     test_loss: 0.559\n",
      "epoch: 4     loss: 0.539     test_loss: 0.556\n",
      "epoch: 5     loss: 0.535     test_loss: 0.552\n",
      "epoch: 6     loss: 0.531     test_loss: 0.548\n",
      "epoch: 7     loss: 0.526     test_loss: 0.544\n",
      "epoch: 8     loss: 0.521     test_loss: 0.539\n",
      "epoch: 9     loss: 0.516     test_loss: 0.534\n",
      "epoch: 10     loss: 0.511     test_loss: 0.529\n",
      "epoch: 11     loss: 0.505     test_loss: 0.524\n",
      "epoch: 12     loss: 0.5     test_loss: 0.519\n",
      "epoch: 13     loss: 0.494     test_loss: 0.513\n",
      "epoch: 14     loss: 0.487     test_loss: 0.507\n",
      "epoch: 15     loss: 0.481     test_loss: 0.501\n",
      "epoch: 16     loss: 0.475     test_loss: 0.495\n",
      "epoch: 17     loss: 0.468     test_loss: 0.489\n",
      "epoch: 18     loss: 0.462     test_loss: 0.483\n",
      "epoch: 19     loss: 0.455     test_loss: 0.476\n",
      "epoch: 20     loss: 0.449     test_loss: 0.47\n",
      "epoch: 21     loss: 0.442     test_loss: 0.464\n",
      "epoch: 22     loss: 0.436     test_loss: 0.457\n",
      "epoch: 23     loss: 0.43     test_loss: 0.451\n",
      "epoch: 24     loss: 0.424     test_loss: 0.445\n",
      "epoch: 25     loss: 0.418     test_loss: 0.439\n",
      "epoch: 26     loss: 0.412     test_loss: 0.433\n",
      "epoch: 27     loss: 0.407     test_loss: 0.427\n",
      "epoch: 28     loss: 0.401     test_loss: 0.422\n",
      "epoch: 29     loss: 0.396     test_loss: 0.417\n",
      "epoch: 30     loss: 0.392     test_loss: 0.412\n",
      "epoch: 31     loss: 0.387     test_loss: 0.408\n",
      "epoch: 32     loss: 0.383     test_loss: 0.403\n",
      "epoch: 33     loss: 0.378     test_loss: 0.399\n",
      "epoch: 34     loss: 0.374     test_loss: 0.395\n",
      "epoch: 35     loss: 0.37     test_loss: 0.39\n",
      "epoch: 36     loss: 0.366     test_loss: 0.386\n",
      "epoch: 37     loss: 0.363     test_loss: 0.382\n",
      "epoch: 38     loss: 0.359     test_loss: 0.379\n",
      "epoch: 39     loss: 0.356     test_loss: 0.375\n",
      "epoch: 40     loss: 0.353     test_loss: 0.372\n",
      "epoch: 41     loss: 0.349     test_loss: 0.369\n",
      "epoch: 42     loss: 0.346     test_loss: 0.365\n",
      "epoch: 43     loss: 0.343     test_loss: 0.362\n",
      "epoch: 44     loss: 0.34     test_loss: 0.359\n",
      "epoch: 45     loss: 0.338     test_loss: 0.356\n",
      "epoch: 46     loss: 0.335     test_loss: 0.353\n",
      "epoch: 47     loss: 0.332     test_loss: 0.35\n",
      "epoch: 48     loss: 0.33     test_loss: 0.348\n",
      "epoch: 49     loss: 0.328     test_loss: 0.345\n",
      "epoch: 50     loss: 0.325     test_loss: 0.343\n",
      "epoch: 51     loss: 0.323     test_loss: 0.34\n",
      "epoch: 52     loss: 0.321     test_loss: 0.338\n",
      "epoch: 53     loss: 0.319     test_loss: 0.336\n",
      "epoch: 54     loss: 0.317     test_loss: 0.334\n",
      "epoch: 55     loss: 0.315     test_loss: 0.331\n",
      "epoch: 56     loss: 0.313     test_loss: 0.33\n",
      "epoch: 57     loss: 0.311     test_loss: 0.328\n",
      "epoch: 58     loss: 0.309     test_loss: 0.325\n",
      "epoch: 59     loss: 0.307     test_loss: 0.324\n",
      "epoch: 60     loss: 0.305     test_loss: 0.322\n",
      "epoch: 61     loss: 0.303     test_loss: 0.319\n",
      "epoch: 62     loss: 0.301     test_loss: 0.318\n",
      "epoch: 63     loss: 0.3     test_loss: 0.316\n",
      "epoch: 64     loss: 0.298     test_loss: 0.314\n",
      "epoch: 65     loss: 0.296     test_loss: 0.312\n",
      "epoch: 66     loss: 0.294     test_loss: 0.31\n",
      "epoch: 67     loss: 0.292     test_loss: 0.308\n",
      "epoch: 68     loss: 0.291     test_loss: 0.307\n",
      "epoch: 69     loss: 0.289     test_loss: 0.305\n",
      "epoch: 70     loss: 0.288     test_loss: 0.303\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     14\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Environment\\miniconda3\\envs\\pytorch2.2.2\\lib\\site-packages\\torch\\_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Environment\\miniconda3\\envs\\pytorch2.2.2\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:489\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m     dynamo_config_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    491\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[1;32md:\\Environment\\miniconda3\\envs\\pytorch2.2.2\\lib\\site-packages\\torch\\optim\\optimizer.py:815\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    813\u001b[0m     per_device_and_dtype_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zero_grad_profile_name):\n\u001b[0;32m    816\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32md:\\Environment\\miniconda3\\envs\\pytorch2.2.2\\lib\\site-packages\\torch\\autograd\\profiler.py:605\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\Environment\\miniconda3\\envs\\pytorch2.2.2\\lib\\site-packages\\torch\\_ops.py:755\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    751\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "model, opt = get_model()\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# if torch.cuda.is_available():\n",
    "#     model = model.to('cuda')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x, y in train_dl:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    with torch.no_grad():\n",
    "        epoch_accuracy = accuracy(model(train_x), train_y).data.item()\n",
    "        epoch_loss = loss_fn(model(train_x), train_y).data.item()\n",
    "\n",
    "        epoch_test_accuracy = accuracy(model(test_x), test_y).data.item()\n",
    "        epoch_test_loss = loss_fn(model(test_x), test_y).data.item()\n",
    "        print('epoch:', epoch, '   ', 'loss:', round(epoch_loss, 3),\n",
    "                               '   ', 'accuracy:', round(epoch_accuracy, 3),\n",
    "                               '   ', 'test_loss:', round(epoch_test_loss, 3),\n",
    "                               '   ', 'test_accuracy:', round(epoch_test_accuracy, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.train()在训练之前调用代表训练模式\n",
    "\n",
    "model.eval() 推理之前进行调用代表推理模式\n",
    "\n",
    "不同的模式仅会在使用nn.BatchNorm2d ，nn.Dropout等层时以确保这些不同阶段的行为正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    if epoch%50==0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss = sum(loss_fn(model(xb), yb) for xb, yb in valid_dl)\n",
    "            acc_mean = np.mean([accuracy(model(xb), yb) for xb, yb in valid_dl])\n",
    "        print(epoch, valid_loss / len(valid_dl), acc_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin_1 = nn.Linear(20, 64)\n",
    "        self.lin_2 = nn.Linear(64, 64)\n",
    "        self.lin_3 = nn.Linear(64, 64)\n",
    "        self.lin_4 = nn.Linear(64, 1)\n",
    "        self.activate = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, input):\n",
    "        x = self.lin_1(input)\n",
    "        x = self.activate(x)\n",
    "        x = self.lin_2(x)\n",
    "        x = self.activate(x)\n",
    "        x = self.lin_3(x)\n",
    "        x = self.activate(x)\n",
    "        x = self.lin_4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "acc_val = []\n",
    "acc_train = []\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    if epoch%50==0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss = sum(loss_fn(model(xb), yb) for xb, yb in valid_dl)\n",
    "            acc_mean_train = np.mean([accuracy(model(xb), yb) for xb, yb in train_dl])\n",
    "            acc_mean_val = np.mean([accuracy(model(xb), yb) for xb, yb in valid_dl])\n",
    "        acc_train.append(acc_mean_train)\n",
    "        acc_val.append(acc_mean_val)\n",
    "        print(epoch, valid_loss / len(valid_dl), acc_mean_train, acc_mean_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建fit（）和get_data（）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 现在，我们获取数据加载器和拟合模型的整个过程可以在3行代码中运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, batch)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_fn, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.2.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
