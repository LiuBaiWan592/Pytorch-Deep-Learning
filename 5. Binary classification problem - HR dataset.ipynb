{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二分类问题-HR数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>part</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years   part  \\\n",
       "0                   3              0     1                      0  sales   \n",
       "1                   6              0     1                      0  sales   \n",
       "2                   4              0     1                      0  sales   \n",
       "3                   5              0     1                      0  sales   \n",
       "4                   3              0     1                      0  sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "data = pd.read_csv('./dataset/HR.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   satisfaction_level     14999 non-null  float64\n",
      " 1   last_evaluation        14999 non-null  float64\n",
      " 2   number_project         14999 non-null  int64  \n",
      " 3   average_montly_hours   14999 non-null  int64  \n",
      " 4   time_spend_company     14999 non-null  int64  \n",
      " 5   Work_accident          14999 non-null  int64  \n",
      " 6   left                   14999 non-null  int64  \n",
      " 7   promotion_last_5years  14999 non-null  int64  \n",
      " 8   part                   14999 non-null  object \n",
      " 9   salary                 14999 non-null  object \n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "['sales' 'accounting' 'hr' 'technical' 'support' 'management' 'IT'\n",
      " 'product_mng' 'marketing' 'RandD']\n",
      "['low' 'medium' 'high']\n"
     ]
    }
   ],
   "source": [
    "# 数据基本信息\n",
    "print(data.info())\n",
    "print(data.part.unique())\n",
    "print(data.salary.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>IT</th>\n",
       "      <th>RandD</th>\n",
       "      <th>...</th>\n",
       "      <th>hr</th>\n",
       "      <th>management</th>\n",
       "      <th>marketing</th>\n",
       "      <th>product_mng</th>\n",
       "      <th>sales</th>\n",
       "      <th>support</th>\n",
       "      <th>technical</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years  IT  RandD  \\\n",
       "0                   3              0     1                      0   0      0   \n",
       "1                   6              0     1                      0   0      0   \n",
       "2                   4              0     1                      0   0      0   \n",
       "3                   5              0     1                      0   0      0   \n",
       "4                   3              0     1                      0   0      0   \n",
       "\n",
       "   ...  hr  management  marketing  product_mng  sales  support  technical  \\\n",
       "0  ...   0           0          0            0      1        0          0   \n",
       "1  ...   0           0          0            0      1        0          0   \n",
       "2  ...   0           0          0            0      1        0          0   \n",
       "3  ...   0           0          0            0      1        0          0   \n",
       "4  ...   0           0          0            0      1        0          0   \n",
       "\n",
       "   high  low  medium  \n",
       "0     0    1       0  \n",
       "1     0    0       1  \n",
       "2     0    0       1  \n",
       "3     0    1       0  \n",
       "4     0    1       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据预处理\n",
    "# 简单的数据分析\n",
    "# data.groupby(['salary', 'part']).size()\n",
    "# .get_dummies()方法可以将分类数据转换为one-hot编码\n",
    "data = data.join(pd.get_dummies(data.part).astype(int)).join(pd.get_dummies(data.salary).astype(int))\n",
    "# 删除原来的分类数据\n",
    "data.drop(columns=['part', 'salary'], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   satisfaction_level     14999 non-null  float64\n",
      " 1   last_evaluation        14999 non-null  float64\n",
      " 2   number_project         14999 non-null  int64  \n",
      " 3   average_montly_hours   14999 non-null  int64  \n",
      " 4   time_spend_company     14999 non-null  int64  \n",
      " 5   Work_accident          14999 non-null  int64  \n",
      " 6   left                   14999 non-null  int64  \n",
      " 7   promotion_last_5years  14999 non-null  int64  \n",
      " 8   IT                     14999 non-null  int32  \n",
      " 9   RandD                  14999 non-null  int32  \n",
      " 10  accounting             14999 non-null  int32  \n",
      " 11  hr                     14999 non-null  int32  \n",
      " 12  management             14999 non-null  int32  \n",
      " 13  marketing              14999 non-null  int32  \n",
      " 14  product_mng            14999 non-null  int32  \n",
      " 15  sales                  14999 non-null  int32  \n",
      " 16  support                14999 non-null  int32  \n",
      " 17  technical              14999 non-null  int32  \n",
      " 18  high                   14999 non-null  int32  \n",
      " 19  low                    14999 non-null  int32  \n",
      " 20  medium                 14999 non-null  int32  \n",
      "dtypes: float64(2), int32(13), int64(6)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left\n",
      "0    11428\n",
      "1     3571\n",
      "Name: count, dtype: int64\n",
      "0.7619174611640777\n"
     ]
    }
   ],
   "source": [
    "# 查看离职率\n",
    "print(data.left.value_counts())\n",
    "# 全部预测为不离职\n",
    "print(data.left.value_counts()[0] / data.left.value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14999, 1])\n"
     ]
    }
   ],
   "source": [
    "# 处理结果数据\n",
    "Y_data = data.left.values.reshape(-1, 1)\n",
    "Y = torch.from_numpy(Y_data).type(torch.FloatTensor)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14999, 20])\n"
     ]
    }
   ],
   "source": [
    "# 处理特征数据\n",
    "# 使用列表推导式，获取除了'left'列之外的所有列\n",
    "# [c for c in data.columns if c != 'left']\n",
    "# 使用.values方法，将DataFrame转换为numpy数组\n",
    "X_data = data[[c for c in data.columns if c != 'left']].values\n",
    "X = torch.from_numpy(X_data).type(torch.FloatTensor)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import nn\n",
    "# # 自定义模型：逻辑回归模型\n",
    "# class Logistic(nn.Module):  # 继承nn.Module\n",
    "#     def __init__(self):     # 初始化所有的层\n",
    "#         super().__init__()  # 继承父类中所有的属性和方法\n",
    "#         self.lin_1 = nn.Linear(20, 64)  # 定义第一层线性层，输入维度为20，输出维度为64\n",
    "#         self.lin_2 = nn.Linear(64, 64)  # 定义第二层线性层，输入维度为64，输出维度为64\n",
    "#         self.lin_3 = nn.Linear(64, 1)   # 定义第三层线性层，输入维度为64，输出维度为1\n",
    "#         self.activate = nn.ReLU()       # 定义ReLU激活函数\n",
    "#         self.sigmoid = nn.Sigmoid()     # 定义Sigmoid激活函数\n",
    "#     def forward(self, input):   # 前向传播函数，定义模型的运算过程，覆盖父类中的forward方法\n",
    "#         x = self.lin_1(input)   # 将输入数据传入第一层线性层\n",
    "#         x = self.activate(x)    # ReLU激活函数\n",
    "#         x = self.lin_2(x)       # 将激活后的数据传入第二层线性层\n",
    "#         x = self.activate(x)    # ReLU激活函数\n",
    "#         x = self.lin_3(x)       # 将激活后的数据传入第三层线性层\n",
    "#         x = self.sigmoid(x)     # Sigmoid激活函数\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型改写\n",
    "from torch import nn\n",
    "import torch.nn.functional as F # 函数式API，调用方便使代码更简洁\n",
    "class Logistic(nn.Module):  # 继承nn.Module\n",
    "    def __init__(self):     # 初始化所有的层\n",
    "        super().__init__()  # 继承父类中所有的属性和方法\n",
    "        self.lin_1 = nn.Linear(20, 64)  # 定义第一层线性层，输入维度为20，输出维度为64\n",
    "        self.lin_2 = nn.Linear(64, 64)  # 定义第二层线性层，输入维度为64，输出维度为64\n",
    "        self.lin_3 = nn.Linear(64, 1)   # 定义第三层线性层，输入维度为64，输出维度为1\n",
    "    def forward(self, input):   # 前向传播函数，定义模型的运算过程，覆盖父类中的forward方法\n",
    "        x = F.relu(self.lin_1(input))   # 将输入数据传入第一层线性层，并使用ReLU激活函数\n",
    "        x = F.relu(self.lin_2(x))       # 将激活后的数据传入第二层线性层，并使用ReLU激活函数\n",
    "        x = F.sigmoid(self.lin_3(x))     # 将激活后的数据传入第三层线性层，并使用Sigmoid激活函数\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Logistic(\n",
      "  (lin_1): Linear(in_features=20, out_features=64, bias=True)\n",
      "  (lin_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (lin_3): Linear(in_features=64, out_features=1, bias=True)\n",
      "), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "# 封装模型和优化器的创建，提高代码复用性\n",
    "lr = 0.0001\n",
    "def get_model():\n",
    "    model = Logistic()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    return model, opt\n",
    "print(get_model())\n",
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割数据集，分批次进行训练\n",
    "batch = 64\n",
    "no_of_batches = len(data)//batch\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 手动分批次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分批次循环训练\n",
    "for epoch in range(epochs):\n",
    "    for i in range(no_of_batches):     # 按照批次进行训练\n",
    "        start = i * batch              # 每个批次的起始索引\n",
    "        end = start + batch                # 每个批次的结束索引\n",
    "        x = X[start: end]\n",
    "        y = Y[start: end]\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(x)\n",
    "        # Compute loss: BCELoss expects the target to be between 0 and 1\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        # Gradient reset\n",
    "        opt.zero_grad()\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update the gradients\n",
    "        opt.step()\n",
    "    with torch.no_grad():\n",
    "        print('epoch:', epoch, '   ', 'loss:', loss_fn(model(X), Y).data.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 使用dataset重构模型训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch有一个抽象的Dataset类。Dataset可以是任何具有__len__函数和__getitem__作为对其进行索引的方法的函数。PyTorch的TensorDataset是一个包装张量的Dataset。通过定义索引的长度和方式，这也为我们提供了沿张量的第一维进行迭代，索引和切片的方法。这将使我们在训练的同一行中更容易访问自变量和因变量。下面将自定义HRDataset类创建为的Dataset的子类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "HRdataset = TensorDataset(X, Y)\n",
    "# print(HRdataset[2: 5])\n",
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0     loss: 0.6582443118095398\n",
      "epoch: 1     loss: 0.6570234894752502\n",
      "epoch: 2     loss: 0.6577951312065125\n",
      "epoch: 3     loss: 0.6454842686653137\n",
      "epoch: 4     loss: 0.628150224685669\n",
      "epoch: 5     loss: 0.6211585998535156\n",
      "epoch: 6     loss: 0.6205790638923645\n",
      "epoch: 7     loss: 0.6005281805992126\n",
      "epoch: 8     loss: 0.5924190878868103\n",
      "epoch: 9     loss: 0.5849792957305908\n",
      "epoch: 10     loss: 0.5797553658485413\n",
      "epoch: 11     loss: 0.5741011500358582\n",
      "epoch: 12     loss: 0.5700239539146423\n",
      "epoch: 13     loss: 0.5669781565666199\n",
      "epoch: 14     loss: 0.5640222430229187\n",
      "epoch: 15     loss: 0.5618149042129517\n",
      "epoch: 16     loss: 0.5604045391082764\n",
      "epoch: 17     loss: 0.5593510270118713\n",
      "epoch: 18     loss: 0.5652616620063782\n",
      "epoch: 19     loss: 0.5600892901420593\n",
      "epoch: 20     loss: 0.5585730671882629\n",
      "epoch: 21     loss: 0.5585653781890869\n",
      "epoch: 22     loss: 0.5586372017860413\n",
      "epoch: 23     loss: 0.5587912797927856\n",
      "epoch: 24     loss: 0.5585929751396179\n",
      "epoch: 25     loss: 0.557896614074707\n",
      "epoch: 26     loss: 0.5599779486656189\n",
      "epoch: 27     loss: 0.560953676700592\n",
      "epoch: 28     loss: 0.5614994764328003\n",
      "epoch: 29     loss: 0.5615630745887756\n",
      "epoch: 30     loss: 0.5622783899307251\n",
      "epoch: 31     loss: 0.5678625702857971\n",
      "epoch: 32     loss: 0.5609281659126282\n",
      "epoch: 33     loss: 0.5614725351333618\n",
      "epoch: 34     loss: 0.5622060894966125\n",
      "epoch: 35     loss: 0.5628795623779297\n",
      "epoch: 36     loss: 0.563025951385498\n",
      "epoch: 37     loss: 0.5626155138015747\n",
      "epoch: 38     loss: 0.5624986290931702\n",
      "epoch: 39     loss: 0.5625231862068176\n",
      "epoch: 40     loss: 0.5623100399971008\n",
      "epoch: 41     loss: 0.5618908405303955\n",
      "epoch: 42     loss: 0.5616031885147095\n",
      "epoch: 43     loss: 0.5658212304115295\n",
      "epoch: 44     loss: 0.5618148446083069\n",
      "epoch: 45     loss: 0.560550332069397\n",
      "epoch: 46     loss: 0.5614158511161804\n",
      "epoch: 47     loss: 0.560094952583313\n",
      "epoch: 48     loss: 0.5637357234954834\n",
      "epoch: 49     loss: 0.5836647152900696\n",
      "epoch: 50     loss: 0.5681132078170776\n",
      "epoch: 51     loss: 0.56200110912323\n",
      "epoch: 52     loss: 0.562041163444519\n",
      "epoch: 53     loss: 0.5600574612617493\n",
      "epoch: 54     loss: 0.559754490852356\n",
      "epoch: 55     loss: 0.5593035221099854\n",
      "epoch: 56     loss: 0.5589854717254639\n",
      "epoch: 57     loss: 0.5582035183906555\n",
      "epoch: 58     loss: 0.5579328536987305\n",
      "epoch: 59     loss: 0.5574698448181152\n",
      "epoch: 60     loss: 0.5568563342094421\n",
      "epoch: 61     loss: 0.5566943287849426\n",
      "epoch: 62     loss: 0.556492805480957\n",
      "epoch: 63     loss: 0.5555631518363953\n",
      "epoch: 64     loss: 0.5555803775787354\n",
      "epoch: 65     loss: 0.5543769598007202\n",
      "epoch: 66     loss: 0.5546414256095886\n",
      "epoch: 67     loss: 0.5521736741065979\n",
      "epoch: 68     loss: 0.5533903241157532\n",
      "epoch: 69     loss: 0.5580515265464783\n",
      "epoch: 70     loss: 0.556267499923706\n",
      "epoch: 71     loss: 0.5525346398353577\n",
      "epoch: 72     loss: 0.5510876774787903\n",
      "epoch: 73     loss: 0.5506421327590942\n",
      "epoch: 74     loss: 0.5500806570053101\n",
      "epoch: 75     loss: 0.5509563684463501\n",
      "epoch: 76     loss: 0.5493165850639343\n",
      "epoch: 77     loss: 0.5502432584762573\n",
      "epoch: 78     loss: 0.5478829741477966\n",
      "epoch: 79     loss: 0.5486406087875366\n",
      "epoch: 80     loss: 0.5472140312194824\n",
      "epoch: 81     loss: 0.5470722317695618\n",
      "epoch: 82     loss: 0.5456418991088867\n",
      "epoch: 83     loss: 0.5451105237007141\n",
      "epoch: 84     loss: 0.5442966222763062\n",
      "epoch: 85     loss: 0.5432082414627075\n",
      "epoch: 86     loss: 0.5423785448074341\n",
      "epoch: 87     loss: 0.5582947731018066\n",
      "epoch: 88     loss: 0.5622974634170532\n",
      "epoch: 89     loss: 0.5656015276908875\n",
      "epoch: 90     loss: 0.5430030822753906\n",
      "epoch: 91     loss: 0.5372706651687622\n",
      "epoch: 92     loss: 0.5335814952850342\n",
      "epoch: 93     loss: 0.5322327017784119\n",
      "epoch: 94     loss: 0.5308987498283386\n",
      "epoch: 95     loss: 0.5297960042953491\n",
      "epoch: 96     loss: 0.539495587348938\n",
      "epoch: 97     loss: 0.5295472741127014\n",
      "epoch: 98     loss: 0.5256384015083313\n",
      "epoch: 99     loss: 0.5258504152297974\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(no_of_batches):\n",
    "        x, y = HRdataset[i * batch: i * batch + batch]\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    with torch.no_grad():\n",
    "        print('epoch:', epoch, '   ', 'loss:', loss_fn(model(X), Y).data.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 使用DataLoader重构模型训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch DataLoader负责管理批次，DataLoader从Dataset创建，自动为我们提供每个小批量，使遍历批次变得更容易，无需使用`HRdataset[i * batch: i * batch + batch]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "HRdataset = TensorDataset(X, Y)\n",
    "HRdataloader = DataLoader(HRdataset, batch_size=batch)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "现在，我们的循环更加简洁了，因为（xb，yb）是从数据加载器自动加载的：\n",
    "\n",
    "for x,y in HR_dl:\n",
    "    pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for x, y in HR_dl:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "print('epoch:', epoch, '   ', 'loss:', loss_fn(model(X), Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 添加验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面我们只是试图建立一个合理的训练循环以用于我们的训练数据。实际上，您始终还应该具有一个验证集，以识别您是否过度拟合。\n",
    "\n",
    "训练数据的乱序（shuffle）对于防止批次与过度拟合之间的相关性很重要。另一方面，无论我们是否乱序验证集，验证损失都是相同的。由于shufle需要额外的开销，因此shuffle验证数据没有任何意义。\n",
    "\n",
    "我们将为验证集使用批大小，该批大小是训练集的两倍。这是因为验证集不需要反向传播，因此占用的内存更少（不需要存储梯度）。我们利用这一优势来使用更大的批量，并更快地计算损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install sklearn -i https://pypi.douban.com/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X_data, Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.from_numpy(train_x).type(torch.FloatTensor)\n",
    "test_x = torch.from_numpy(test_x).type(torch.FloatTensor)\n",
    "train_y = torch.from_numpy(train_y).type(torch.FloatTensor)\n",
    "test_y = torch.from_numpy(test_y).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(train_x, train_y)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(test_x, test_y)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义计算正确率函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = (out>0.5).type(torch.IntTensor)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.train()在训练之前调用代表训练模式\n",
    "\n",
    "model.eval() 推理之前进行调用代表推理模式\n",
    "\n",
    "不同的模式仅会在使用nn.BatchNorm2d ，nn.Dropout等层时以确保这些不同阶段的行为正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    if epoch%50==0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss = sum(loss_fn(model(xb), yb) for xb, yb in valid_dl)\n",
    "            acc_mean = np.mean([accuracy(model(xb), yb) for xb, yb in valid_dl])\n",
    "        print(epoch, valid_loss / len(valid_dl), acc_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin_1 = nn.Linear(20, 64)\n",
    "        self.lin_2 = nn.Linear(64, 64)\n",
    "        self.lin_3 = nn.Linear(64, 64)\n",
    "        self.lin_4 = nn.Linear(64, 1)\n",
    "        self.activate = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, input):\n",
    "        x = self.lin_1(input)\n",
    "        x = self.activate(x)\n",
    "        x = self.lin_2(x)\n",
    "        x = self.activate(x)\n",
    "        x = self.lin_3(x)\n",
    "        x = self.activate(x)\n",
    "        x = self.lin_4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "acc_val = []\n",
    "acc_train = []\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    if epoch%50==0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss = sum(loss_fn(model(xb), yb) for xb, yb in valid_dl)\n",
    "            acc_mean_train = np.mean([accuracy(model(xb), yb) for xb, yb in train_dl])\n",
    "            acc_mean_val = np.mean([accuracy(model(xb), yb) for xb, yb in valid_dl])\n",
    "        acc_train.append(acc_mean_train)\n",
    "        acc_val.append(acc_mean_val)\n",
    "        print(epoch, valid_loss / len(valid_dl), acc_mean_train, acc_mean_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建fit（）和get_data（）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 现在，我们获取数据加载器和拟合模型的整个过程可以在3行代码中运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, batch)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_fn, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.2.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
